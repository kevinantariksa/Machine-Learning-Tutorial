{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML0120EN-5.1-Review-Autoencoders.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.13"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOTfR0KH2AcG",
        "colab_type": "text"
      },
      "source": [
        "<img src = \"https://i.imgur.com/UjutVJd.jpg\" align = \"center\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqNZ7vJI2AcI",
        "colab_type": "text"
      },
      "source": [
        "<h1>AUTOENCODERS</h1>\n",
        "\n",
        "Welcome to this notebook about autoencoders. In this notebook you will find an explanation of what is an autoencoder, how it works, and see an implementation of an autoencoder in TensorFlow.\n",
        "\n",
        "# Table of Contents\n",
        "<p>- <a href=\"#ref1\">Introduction</a></p>\n",
        "<p>- <a href=\"#ref2\">Feature Extraction and Dimensionality Reduction</a></p>\n",
        "<p>- <a href=\"#ref3\">Autoencoder Structure</a></p>\n",
        "<p>- <a href=\"#ref4\">Performance</a></p>\n",
        "<p>- <a href=\"#ref5\">Training: Loss Function</a></p>\n",
        "<p>- <a href=\"#ref6\">Code</a></p>\n",
        "<p></p>\n",
        "By the end of this notebook, you should be able to create simple autoencoders and how to apply them in problems.\n",
        "</div>\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "----------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYeZPNrx2AcJ",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"ref1\"></a>\n",
        "# Introduction\n",
        "An autoencoder, also known as autoassociator or Diabolo networks, is a artificial neural network employed to recreate the given input.\n",
        "It takes a set of **unlabeled** inputs, encodes them and then tries to extract the most valuable information from them.\n",
        "They are used for feature extraction, learning generative models of data, dimensionality reduction and can be used for compression. \n",
        "\n",
        "A 2006 paper named Reducing the Dimensionality of Data with Neural Networks, done by G. E. Hinton and R. R. Salakhutdinov, showed better results than years of refining other types of network, and was a breakthrough in the field of Neural Networks, a field that was \"stagnant\" for 10 years.\n",
        "\n",
        "Now, autoencoders, based on Restricted Boltzmann Machines, are employed in some of the largest deep learning applications. They are the building blocks of Deep Belief Networks (DBN).\n",
        "\n",
        "<img src = \"https://ibm.box.com/shared/static/xlkv9v7xzxhjww681dq3h1pydxcm4ktp.png\" style=\"width: 350px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa9oEgRF2AcM",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"ref2\"></a>\n",
        "# Feature Extraction and Dimensionality Reduction\n",
        "\n",
        "An example given by Nikhil Buduma in KdNuggets (<a href=\"http://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html\">link</a>) can explain the utility of this type of Neural Network with excellence.\n",
        "\n",
        "Say that you want to extract what feeling the person in a photography is feeling. Using as an example the following 256x256 grayscale picture:\n",
        "\n",
        "<img src = \"https://ibm.box.com/shared/static/r5knpow4bk2farlvxia71e9jp2f2u126.png\" />\n",
        "\n",
        "But then we start facing a bottleneck! This image being 256x256 correspond with an input vector of 65536 dimensions! If we used an image produced with convential cellphone cameras, that generates images of 4000 x 3000 pixels, we would have 12 million dimensions to analyse.\n",
        "\n",
        "\n",
        "This bottleneck is further problematized as the difficulty of a machine learning problem is increased as more dimensions are involved. According to a 1982 study by C.J. Stone (<a href=\"http://www-personal.umich.edu/~jizhu/jizhu/wuke/Stone-AoS82.pdf\">link</a>), the time to fit a model, at best, is:\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "<center><font size = 6><strong>$m^{-p/(2p+d)}$</strong></font></center>\n",
        "<br>\n",
        "Where:\n",
        "<br>\n",
        "m: Number of data points\n",
        "<br>\n",
        "d: Dimensionality of the data\n",
        "<br>\n",
        "p: Parameter that depends on the model\n",
        "</div>\n",
        "\n",
        "As you can see, it increases exponentially!\n",
        "Returning to our example, we don't need to use all of the 65,536 dimensions to classify an emotion. A human identify emotions according to some specific facial expression, some **key features**, like the shape of the mouth and eyebrows.\n",
        "\n",
        "<img src=\"https://ibm.box.com/shared/static/m8urvuqujkt2vt1ru1fnslzh24pv7hn4.png\" height=\"256\" width=\"256\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02UdPiPI2AcN",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-graUucc2AcO",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"ref3\"></a>\n",
        "# Autoencoder Structure\n",
        "\n",
        "<img src=\"https://ibm.box.com/shared/static/no7omt2jhqvv7uuls7ihnzikyl9ysnfp.png\" style=\"width: 400px;\"/>\n",
        "\n",
        "An autoencoder can be divided in two parts, the **encoder** and the **decoder**.\n",
        "\n",
        "The encoder needs to compress the representation of an input. In this case we are going to compress the face of our actor, that consists of 2000 dimensional data to only 30 dimensions, taking some steps between this compression.\n",
        "\n",
        "The decoder is a reflection of the encoder network. It works to recreate the input, as closely as possible. It has an important role during training, to force the autoencoder to select the most important features in the compressed representation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esOKKyCH2AcP",
        "colab_type": "text"
      },
      "source": [
        "--------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcKSvPEZ2AcQ",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"ref4\"></a>\n",
        "# Performance\n",
        "\n",
        "After the training has been done, you can use the encoded data as a reliable dimensionally-reduced data, applying it to any problems that a dimensionality reduction problem seem to fit.\n",
        "\n",
        "<img src=\"https://ibm.box.com/shared/static/yt3xyon4g2jyw1w9qup1mvx7cgh28l64.png\"/>\n",
        "\n",
        "This image was extracted from the Hinton paper comparing the two-dimensional reduction for 500 digits of the MNIST, with PCA on the left and autoencoder on the right. We can see that the autoencoder provided us with a better separation of data.\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBaLONt52AcS",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"ref5\"></a>\n",
        "# Training: Loss function\n",
        "\n",
        "An autoencoder uses the Loss function to properly train the network. The Loss function will calculate the differences between our output and the expected results. After that, we can minimize this error doing gradient descent. There are more than one type of Loss function, it depends on the type of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWJ6p3Mu2AcT",
        "colab_type": "text"
      },
      "source": [
        "### Binary Values:\n",
        "$$l(f(x)) = - \\sum_{k} (x_k log(\\hat{x}_k) + (1 - x_k) \\log (1 - \\hat{x}_k) \\ )$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIbY_Qrl2AcU",
        "colab_type": "text"
      },
      "source": [
        "For binary values, we can use an equation based on the sum of Bernoulli's cross-entropy. \n",
        "\n",
        "$x_k$ is one of our inputs and $\\hat{x}_k$ is the respective output.\n",
        "\n",
        "We use this function so that if $x_k$ equals to one, we want to push $\\hat{x}_k$ as close as possible to one. The same if $x_k$ equals to zero.\n",
        "\n",
        "If the value is one, we just need to calculate the first part of the formula, that is, $- x_k log(\\hat{x}_k)$. Which, turns out to just calculate $- log(\\hat{x}_k)$.\n",
        "\n",
        "And if the value is zero, we need to calculate just the second part, $(1 - x_k) \\log (1 - \\hat{x}_k) \\ )$ - which turns out to be $log (1 - \\hat{x}_k) $.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ky13cVU2AcV",
        "colab_type": "text"
      },
      "source": [
        "### Real values:\n",
        "$$l(f(x)) = - 1/2\\sum_{k} (\\hat{x}_k- x_k \\ )^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VtmfUrx2AcW",
        "colab_type": "text"
      },
      "source": [
        "As the above function would behave badly with inputs that are not 0 or 1, we can use the sum of squared differences for our Loss function. If you use this loss function, it's necessary that you use a linear activation function for the output layer.\n",
        "\n",
        "As it was with the above example, $x_k$ is one of our inputs and $\\hat{x}_k$ is the respective output, and we want to make our output as similar as possible to our input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-8Sa5I-2AcX",
        "colab_type": "text"
      },
      "source": [
        "### Loss Gradient:\n",
        "\n",
        "$$\\nabla_{\\hat{a}(x^{(t)})} \\ l( \\ f(x^{(t)}))  = \\hat{x}^{(t)} - x^{(t)} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KC1-c6Bh2AcY",
        "colab_type": "text"
      },
      "source": [
        "We use the gradient descent to reach the local minumum of our function $l( \\ f(x^{(t)})$, taking steps towards the negative of the gradient of the function in the current point.\n",
        "\n",
        "Our function talks about the preactivation of the output layer $(\\nabla_{\\hat{a}(x^{(t)})})$ of the loss $l( \\ f(x^{(t)})$.\n",
        "\n",
        "It's actually a simple formula, it just calculates the difference between our output $\\hat{x}^{(t)}$ and our input $x^{(t)}$.\n",
        "\n",
        "Then our network just backpropagates our gradient $\\nabla_{\\hat{a}(x^{(t)})} \\ l( \\ f(x^{(t)}))$ through the network using **backpropagation**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY4p20Ac2AcZ",
        "colab_type": "text"
      },
      "source": [
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q4tFbTE2Aca",
        "colab_type": "text"
      },
      "source": [
        "<a id=\"ref6\"></a>\n",
        "# Code\n",
        "\n",
        "For this part, we walk through a lot of Python 2.7.11 code. We are going to use the MNIST dataset for our example.\n",
        "The following code was created by Aymeric Damien. You can find some of his code in [here](https://github.com/aymericdamien). There are just some modifications for us to import the datasets to Jupyter Notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi1QAcv42Acb",
        "colab_type": "text"
      },
      "source": [
        "Let's call our imports and make the MNIST data available to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgZTj43F2Acc",
        "colab_type": "code",
        "outputId": "fb9f24d0-ed97-475a-b8b5-0080518aeb8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Import MINST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0813 01:59:58.642008 139942376171392 deprecation.py:323] From <ipython-input-1-47aa9ec4e012>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0813 01:59:58.643771 139942376171392 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0813 01:59:58.645190 139942376171392 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "W0813 02:00:03.955452 139942376171392 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0813 02:00:04.468792 139942376171392 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0813 02:00:04.474236 139942376171392 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0813 02:00:04.749653 139942376171392 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3fWySOr2Ach",
        "colab_type": "text"
      },
      "source": [
        "Now, let's give the parameters that are going to be used by our NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-3Py6vO2Aci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.01\n",
        "training_epochs = 20\n",
        "batch_size = 256\n",
        "display_step = 1\n",
        "examples_to_show = 10\n",
        "\n",
        "# Network Parameters\n",
        "n_hidden_1 = 256 # 1st layer num features\n",
        "n_hidden_2 = 128 # 2nd layer num features\n",
        "n_input = 784 # MNIST data input (img shape: 28*28)\n",
        "\n",
        "# tf Graph input (only pictures)\n",
        "X = tf.placeholder(\"float\", [None, n_input])\n",
        "\n",
        "weights = {\n",
        "    'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
        "    'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
        "    'decoder_h1': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n",
        "    'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n",
        "}\n",
        "biases = {\n",
        "    'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
        "    'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
        "    'decoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
        "    'decoder_b2': tf.Variable(tf.random_normal([n_input])),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF73e36H2Acm",
        "colab_type": "text"
      },
      "source": [
        "Now we need to create our encoder. For this, we are going to use sigmoidal functions. Sigmoidal functions continue to deliver great results with this type of networks. This is due to having a good derivative that is well-suited to backpropagation. We can create our encoder using the sigmoidal function like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSuUq4i12Acn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the encoder\n",
        "def encoder(x):\n",
        "    # Encoder first layer with sigmoid activation #1\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']),\n",
        "                                   biases['encoder_b1']))\n",
        "    # Encoder second layer with sigmoid activation #2\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
        "                                   biases['encoder_b2']))\n",
        "    return layer_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y5046at2Acx",
        "colab_type": "text"
      },
      "source": [
        "And the decoder:\n",
        "\n",
        "You can see that the layer_1 in the encoder is the layer_2 in the decoder and vice-versa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfBLuMPq2Acy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the decoder\n",
        "def decoder(x):\n",
        "    # Decoder first layer with sigmoid activation #1\n",
        "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),\n",
        "                                   biases['decoder_b1']))\n",
        "    # Decoder second layer with sigmoid activation #2\n",
        "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
        "                                   biases['decoder_b2']))\n",
        "    return layer_2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYvCVY-i2Ac1",
        "colab_type": "text"
      },
      "source": [
        "Let's construct our model.\n",
        "In the variable `cost` we have the loss function and in the `optimizer` variable we have our gradient used for backpropagation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woEVPamT2Ac2",
        "colab_type": "code",
        "outputId": "3c597363-851b-492d-c3d4-326de1f9a03e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# Construct model\n",
        "encoder_op = encoder(X)\n",
        "decoder_op = decoder(encoder_op)\n",
        "\n",
        "# Prediction\n",
        "y_pred = decoder_op\n",
        "# Targets (Labels) are the input data.\n",
        "y_true = X\n",
        "\n",
        "# Define loss and optimizer, minimize the squared error\n",
        "cost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0813 02:00:05.258263 139942376171392 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1205: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0813 02:00:05.480385 139942376171392 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/training/rmsprop.py:119: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "artdmbYN2Ac5",
        "colab_type": "text"
      },
      "source": [
        "The training will run for 20 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGU-xK5O2Ac6",
        "colab_type": "code",
        "outputId": "15ff1f23-483e-4e09-aa5b-dc02925f6c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "# Launch the graph\n",
        "# Using InteractiveSession (more convenient while using Notebooks)\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(init)\n",
        "\n",
        "total_batch = int(mnist.train.num_examples/batch_size)\n",
        "# Training cycle\n",
        "for epoch in range(training_epochs):\n",
        "    # Loop over all batches\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        # Run optimization op (backprop) and cost op (to get loss value)\n",
        "        _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n",
        "    # Display logs per epoch step\n",
        "    if epoch % display_step == 0:\n",
        "        print(\"Epoch:\", '%04d' % (epoch+1),\n",
        "              \"cost=\", \"{:.9f}\".format(c))\n",
        "\n",
        "print(\"Optimization Finished!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost= 0.212688372\n",
            "Epoch: 0002 cost= 0.175756529\n",
            "Epoch: 0003 cost= 0.151808456\n",
            "Epoch: 0004 cost= 0.141613185\n",
            "Epoch: 0005 cost= 0.134478748\n",
            "Epoch: 0006 cost= 0.126605481\n",
            "Epoch: 0007 cost= 0.120623469\n",
            "Epoch: 0008 cost= 0.117224306\n",
            "Epoch: 0009 cost= 0.114378899\n",
            "Epoch: 0010 cost= 0.110142380\n",
            "Epoch: 0011 cost= 0.106288910\n",
            "Epoch: 0012 cost= 0.105914973\n",
            "Epoch: 0013 cost= 0.105305225\n",
            "Epoch: 0014 cost= 0.100519300\n",
            "Epoch: 0015 cost= 0.101496942\n",
            "Epoch: 0016 cost= 0.099407293\n",
            "Epoch: 0017 cost= 0.097641557\n",
            "Epoch: 0018 cost= 0.093888924\n",
            "Epoch: 0019 cost= 0.093271278\n",
            "Epoch: 0020 cost= 0.092924081\n",
            "Optimization Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yuc2gKQr2Ac_",
        "colab_type": "text"
      },
      "source": [
        "Now, let's apply encode and decode for our tests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-pUjzcI2AdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying encode and decode over test set\n",
        "encode_decode = sess.run(\n",
        "    y_pred, feed_dict={X: mnist.test.images[:examples_to_show]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB2QBjBF2AdE",
        "colab_type": "text"
      },
      "source": [
        "Let's simply visualize our graphs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg_XXwQL2AdF",
        "colab_type": "code",
        "outputId": "8f50960a-3756-45de-f2df-b438e6f9ce11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "# Compare original images with their reconstructions\n",
        "f, a = plt.subplots(2, 10, figsize=(10, 2))\n",
        "for i in range(examples_to_show):\n",
        "    a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
        "    a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAACNCAYAAACT6v+eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 720x144 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_CIKd6j2AdJ",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the reconstructions were successful. It can be seen that some noise was added to the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFhaq2Rt2AdK",
        "colab_type": "text"
      },
      "source": [
        "## Want to learn more?\n",
        "\n",
        "Running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBM's Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The PowerAI platform supports popular machine learning libraries and dependencies including Tensorflow, Caffe, Torch, and Theano. You can download a [free version of PowerAI](https://cocl.us/ML0120EN_PAI).\n",
        "\n",
        "Also, you can use Data Science Experience to run these notebooks faster with bigger datasets. Data Science Experience is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, DSX enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of DSX users today with a free account at [Data Science Experience](https://cocl.us/ML0120EN_DSX)This is the end of this lesson. Hopefully, now you have a deeper and intuitive understanding regarding the LSTM model. Thank you for reading this notebook, and good luck on your studies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRsaOmZf2AdL",
        "colab_type": "text"
      },
      "source": [
        "# Thanks for completing this lesson!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlSrTXpL2AdM",
        "colab_type": "text"
      },
      "source": [
        "Authors:\n",
        "\n",
        "- <a href = \"https://www.linkedin.com/in/franciscomagioli\">Francisco Magioli</a>\n",
        "- <a href = \"https://ca.linkedin.com/in/erich-natsubori-sato\">Erich Natsubori Sato</a>\n",
        "- Gabriel Garcez Barros Souza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_QYCIOy2AdN",
        "colab_type": "text"
      },
      "source": [
        "### References:\n",
        "- https://en.wikipedia.org/wiki/Autoencoder\n",
        "- http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/\n",
        "- http://www.slideshare.net/billlangjun/simple-introduction-to-autoencoder\n",
        "- http://www.slideshare.net/danieljohnlewis/piotr-mirowski-review-autoencoders-deep-learning-ciuuk14\n",
        "- https://cs.stanford.edu/~quocle/tutorial2.pdf\n",
        "- https://gist.github.com/hussius/1534135a419bb0b957b9\n",
        "- http://www.deeplearningbook.org/contents/autoencoders.html\n",
        "- http://www.kdnuggets.com/2015/03/deep-learning-curse-dimensionality-autoencoders.html/\n",
        "- https://www.youtube.com/watch?v=xTU79Zs4XKY\n",
        "- http://www-personal.umich.edu/~jizhu/jizhu/wuke/Stone-AoS82.pdf\n",
        "- Reducing the Dimensionality of Data with Neural Networks, G. E. Hinton, R. R. Salakhutdinov, Science  28 Jul 2006, Vol. 313, Issue 5786, pp. 504-507, DOI: 10.1126/science.1127647 - http://science.sciencemag.org/content/313/5786/504.full\n",
        "\n",
        "<hr>\n",
        "\n",
        "<p>Copyright &copy; 2017 IBM <a href=\"https://cognitiveclass.ai/?utm_source=ML0151&utm_medium=lab&utm_campaign=cclab\">IBM Cognitive Class</a>. This notebook and its source code are released under the terms of the <a href=\"https://cognitiveclass.ai/mit-license/\">MIT License</a>.</p>\n"
      ]
    }
  ]
}