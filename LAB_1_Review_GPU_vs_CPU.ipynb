{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB-1-Review-GPU_vs_CPU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb5RkURI7G9G",
        "colab_type": "text"
      },
      "source": [
        "<img src = \"https://i.imgur.com/UjutVJd.jpg\"  align = \"center\">\n",
        "<h1><font size = 5>GPU vs CPU</font></h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLwg60wO7G9K",
        "colab_type": "text"
      },
      "source": [
        "In this notebook we learn how to run a program on different devices.\n",
        "\n",
        "There are usually multiple computing devices available on each machine. TensorFlow, supports three types of devices:\n",
        "- \"/cpu:0\": The CPU of your machine.\n",
        "- \"/gpu:0\": The GPU of your machine, if you have one.\n",
        "- \"/device:XLA:0\": Optimized domain-specific compiler for linear algebra.\n",
        "\n",
        "**Note: Use Change runtime  if  error occured, choose  Hardware Accelerator **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5JuLG607G9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "config.log_device_placement=False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "R2Sl5M-V7G9Y",
        "colab_type": "text"
      },
      "source": [
        "### List of CPU and GPUs\n",
        "How to get list of CPU and GPUs on your machine ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "tSORdtzm7G9b",
        "colab_type": "code",
        "outputId": "56cc3ce0-5824-450f-d32c-7845f4524a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos]\n",
        "get_available_gpus()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[u'/device:CPU:0',\n",
              " u'/device:XLA_CPU:0',\n",
              " u'/device:XLA_GPU:0',\n",
              " u'/device:GPU:0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXlJ88Q97G9k",
        "colab_type": "text"
      },
      "source": [
        "You might see one CPU, one or more GPUs if it is available on your computer, and also XLA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "j7pEAvaS7G9n",
        "colab_type": "text"
      },
      "source": [
        "#### Performance of GPU vs CPU\n",
        "Most of Deep Learning models, especially in their training phase, involve a lot of matrix and vector multiplications that can parallelized. In this case, GPUs can overperform CPUs, because GPUs were designed to handle these kind of matrix operations in parallel!\n",
        "\n",
        "#### Why GPU overperforms?\n",
        "A single core CPU takes a matrix operation in serial, one element at a time. But, a single GPU could have hundreds or thousands of cores, while a CPU typically has no more than a few cores.\n",
        "\n",
        "\n",
        "#### How to use GPU with TensorFlow?\n",
        "It is important to notice that if both CPU and GPU are available on the machine that you are running a noebook, and if a TensorFlow operation has both CPU and GPU implementations, the GPU devices will be given priority when the operation is assigned to a device. \n",
        "\n",
        "In our case, as we are running this notebook on [IBM PowerAI](http://cocl.us/SETI-NIMBIX-PowerAI), you hvae access to multi GPU, but lets use one of the GPUs in this notebook, for the sake of simplicity.\n",
        "\n",
        "#### What is XLA?  \n",
        "XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear algebra that optimizes TensorFlow computations. The results are improvements in speed, memory usage, and portability on server and mobile platforms. Initially, most users will not see large benefits from XLA, but are welcome to experiment by using XLA via just-in-time (JIT) compilation or ahead-of-time (AOT) compilation. Developers targeting new hardware accelerators are especially encouraged to try out XLA.\n",
        "\n",
        "The XLA framework is experimental and in active development. In particular, while it is unlikely that the semantics of existing operations will change, it is expected that more operations will be added to cover important use cases. The team welcomes feedback from the community about missing functionality and community contributions via GitHub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06odezLw7G9s",
        "colab_type": "text"
      },
      "source": [
        "### Logging device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Bjs3r3-I7G9w",
        "colab_type": "text"
      },
      "source": [
        "It is recommended to use __logging device placement__ when using GPUs, as this lets you easily debug issues relating to different device usage. This prints the usage of devices to the log, allowing you to see when devices change and how that affects the graph. Unfortunately, the currenct version of jupyter notbeook does not show the logs properly, but still you can print out the nodes as a json file and check the devices. It will work fine if your script is running outside of Jupyter though. \n",
        "\n",
        "You can see that a, b and c are all run on GPU0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae4NbIC_7G9y",
        "colab_type": "code",
        "outputId": "4fb491a9-cb66-4fd0-a9d9-ada958fe0c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def print_logging_device():\n",
        "    # Creates a graph.\n",
        "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
        "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
        "    c = tf.constant([1.0, 2.0, 3.0, 4.0, ], shape=[2, 2], name='c')\n",
        "    mu = tf.matmul(a, b)\n",
        "    # Creates a session with log_device_placement set to True.\n",
        "    sess = tf.Session(config=config)\n",
        "    # Runs the op.\n",
        "    options = tf.RunOptions(output_partition_graphs=True)\n",
        "    metadata = tf.RunMetadata()\n",
        "    c_val = sess.run(mu, options=options, run_metadata=metadata)\n",
        "    print (c_val)\n",
        "    print (metadata.partition_graphs)\n",
        "\n",
        "print_logging_device()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[22. 28.]\n",
            " [49. 64.]]\n",
            "[node {\n",
            "  name: \"MatMul\"\n",
            "  op: \"Const\"\n",
            "  device: \"/job:localhost/replica:0/task:0/device:GPU:0\"\n",
            "  attr {\n",
            "    key: \"dtype\"\n",
            "    value {\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"value\"\n",
            "    value {\n",
            "      tensor {\n",
            "        dtype: DT_FLOAT\n",
            "        tensor_shape {\n",
            "          dim {\n",
            "            size: 2\n",
            "          }\n",
            "          dim {\n",
            "            size: 2\n",
            "          }\n",
            "        }\n",
            "        tensor_content: \"\\000\\000\\260A\\000\\000\\340A\\000\\000DB\\000\\000\\200B\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "  experimental_debug_info {\n",
            "    original_node_names: \"MatMul\"\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"MatMul/_0\"\n",
            "  op: \"_Send\"\n",
            "  input: \"MatMul\"\n",
            "  device: \"/job:localhost/replica:0/task:0/device:GPU:0\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"client_terminated\"\n",
            "    value {\n",
            "      b: false\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"recv_device\"\n",
            "    value {\n",
            "      s: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"send_device\"\n",
            "    value {\n",
            "      s: \"/job:localhost/replica:0/task:0/device:GPU:0\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"send_device_incarnation\"\n",
            "    value {\n",
            "      i: 1\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"tensor_name\"\n",
            "    value {\n",
            "      s: \"edge_5_MatMul\"\n",
            "    }\n",
            "  }\n",
            "  experimental_debug_info {\n",
            "    original_node_names: \"MatMul\"\n",
            "  }\n",
            "}\n",
            "library {\n",
            "}\n",
            "versions {\n",
            "  producer: 38\n",
            "}\n",
            ", node {\n",
            "  name: \"MatMul/_1\"\n",
            "  op: \"_Recv\"\n",
            "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
            "  attr {\n",
            "    key: \"client_terminated\"\n",
            "    value {\n",
            "      b: false\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"recv_device\"\n",
            "    value {\n",
            "      s: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"send_device\"\n",
            "    value {\n",
            "      s: \"/job:localhost/replica:0/task:0/device:GPU:0\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"send_device_incarnation\"\n",
            "    value {\n",
            "      i: 1\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"tensor_name\"\n",
            "    value {\n",
            "      s: \"edge_5_MatMul\"\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"tensor_type\"\n",
            "    value {\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "  experimental_debug_info {\n",
            "    original_node_names: \"MatMul\"\n",
            "  }\n",
            "}\n",
            "node {\n",
            "  name: \"_retval_MatMul_0_0\"\n",
            "  op: \"_Retval\"\n",
            "  input: \"MatMul/_1\"\n",
            "  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\n",
            "  attr {\n",
            "    key: \"T\"\n",
            "    value {\n",
            "      type: DT_FLOAT\n",
            "    }\n",
            "  }\n",
            "  attr {\n",
            "    key: \"index\"\n",
            "    value {\n",
            "      i: 0\n",
            "    }\n",
            "  }\n",
            "  experimental_debug_info {\n",
            "    original_node_names: \"_retval_MatMul_0_0\"\n",
            "  }\n",
            "}\n",
            "library {\n",
            "}\n",
            "versions {\n",
            "  producer: 38\n",
            "}\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3se9M0dc7G94",
        "colab_type": "text"
      },
      "source": [
        "#### What types of operations should I send to the GPU?\n",
        "\n",
        "Basically, if a step of the process encompass “do this mathematical operation many times”, then it is a good candidate operation to send it to be run on the GPU. For example,\n",
        "- Matrix multiplication \n",
        "- Computing the inverse of a matrix.\n",
        "- Gradient calculation, which are computed on multiple GPUs individually and are averaged on CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hRmpYJw7G97",
        "colab_type": "text"
      },
      "source": [
        "### Device placement:\n",
        "As mentioned, by default, GPU get priority for the operations which support runing on it. But, you can manually place an operation on a device to be run. You can use __ tf.device__ to assign the operations to a device context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAPzNwhJ7G9_",
        "colab_type": "code",
        "outputId": "83d8fe0f-36ff-43bb-cd29-16f467b89884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Creates a new graph.\n",
        "myGraph = tf.Graph()\n",
        "with tf.Session(config=config, graph=myGraph) as sess:\n",
        "    with tf.device('/gpu:0'):\n",
        "        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
        "        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
        "        c = tf.constant([1.0, 2.0, 3.0, 4.0, ], shape=[2, 2], name='c')\n",
        "        mu = tf.matmul(a, b)\n",
        "    with tf.device('/cpu:0'):\n",
        "        ad = tf.add(mu,c)\n",
        "    print (sess.run(ad))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[23. 30.]\n",
            " [52. 68.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF-nNun27G-I",
        "colab_type": "text"
      },
      "source": [
        "Lets use one of Alex Mordvintsev deep dream [notebook]() to visualize the above graph. You can change the color to see the operations assigned to GPU and CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRtyenbm7G-L",
        "colab_type": "code",
        "outputId": "8235a303-303a-4ae2-89bb-1bc9a13aa794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        }
      },
      "source": [
        "# Helper functions for TF Graph visualization\n",
        "from IPython.display import clear_output, Image, display, HTML\n",
        "\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = strip_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        if n.op == 'Const':\n",
        "            tensor = n.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = tf.compat.as_bytes(\"<stripped %d bytes>\"%size)\n",
        "    return strip_def\n",
        "  \n",
        "def rename_nodes(graph_def, rename_func):\n",
        "    res_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = res_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        n.name = rename_func(n.name)\n",
        "        for i, s in enumerate(n.input):\n",
        "            n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
        "    return res_def\n",
        "  \n",
        "def show_graph(graph_def, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "  \n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "    display(HTML(iframe))\n",
        "\n",
        "graph_def = myGraph.as_graph_def()\n",
        "tmp_def = rename_nodes(graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
        "show_graph(tmp_def)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"\n",
              "        <script>\n",
              "          function load() {\n",
              "            document.getElementById(&quot;graph0.458164052832&quot;).pbtxt = 'node {\\n  name: &quot;a&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:GPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n          dim {\\n            size: 3\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\200?\\\\000\\\\000\\\\000@\\\\000\\\\000@@\\\\000\\\\000\\\\200@\\\\000\\\\000\\\\240@\\\\000\\\\000\\\\300@&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;b&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:GPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3\\n          }\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\200?\\\\000\\\\000\\\\000@\\\\000\\\\000@@\\\\000\\\\000\\\\200@\\\\000\\\\000\\\\240@\\\\000\\\\000\\\\300@&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;c&quot;\\n  op: &quot;Const&quot;\\n  device: &quot;/device:GPU:0&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\000\\\\000\\\\200?\\\\000\\\\000\\\\000@\\\\000\\\\000@@\\\\000\\\\000\\\\200@&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;a&quot;\\n  input: &quot;b&quot;\\n  device: &quot;/device:GPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;MatMul&quot;\\n  input: &quot;c&quot;\\n  device: &quot;/device:CPU:0&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\n';\n",
              "          }\n",
              "        </script>\n",
              "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
              "        <div style=&quot;height:600px&quot;>\n",
              "          <tf-graph-basic id=&quot;graph0.458164052832&quot;></tf-graph-basic>\n",
              "        </div>\n",
              "    \"></iframe>\n",
              "    "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERdpAqfm7G-V",
        "colab_type": "text"
      },
      "source": [
        "### Multiplication on GPU and CPU\n",
        "In teh following cell, we define a function, to measure the speed of matrix multiplication in CPU and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "mIOYUQxB7G-u",
        "colab_type": "code",
        "outputId": "5a211e11-7b85-4e7b-a494-91243aa1a661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "source": [
        "def matrix_mul(device_name, matrix_sizes):\n",
        "    time_values = []\n",
        "    #device_name = \"/cpu:0\"\n",
        "    for size in matrix_sizes:\n",
        "        with tf.device(device_name):\n",
        "            random_matrix = tf.random_uniform(shape=(2,2), minval=0, maxval=1)\n",
        "            dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))\n",
        "            sum_operation = tf.reduce_sum(dot_operation)\n",
        "\n",
        "        with tf.Session(config=tf.ConfigProto(log_device_placement=False)) as session:\n",
        "            startTime = datetime.now()\n",
        "            result = session.run(sum_operation)\n",
        "        td = datetime.now() - startTime\n",
        "        time_values.append(td.microseconds/1000)\n",
        "        print (\"matrix shape:\" + str(size) + \"  --\"+ device_name +\" time: \"+str(td.microseconds/1000))\n",
        "    return time_values\n",
        "\n",
        "\n",
        "matrix_sizes = range(100,1000,100)\n",
        "time_values_gpu = matrix_mul(\"/gpu:0\", matrix_sizes)\n",
        "time_values_cpu = matrix_mul(\"/cpu:0\", matrix_sizes)\n",
        "print (\"GPU time\" +  str(time_values_gpu))\n",
        "print (\"CPU time\" + str(time_values_cpu))\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "matrix shape:100  --/gpu:0 time: 678\n",
            "matrix shape:200  --/gpu:0 time: 6\n",
            "matrix shape:300  --/gpu:0 time: 7\n",
            "matrix shape:400  --/gpu:0 time: 7\n",
            "matrix shape:500  --/gpu:0 time: 6\n",
            "matrix shape:600  --/gpu:0 time: 6\n",
            "matrix shape:700  --/gpu:0 time: 4\n",
            "matrix shape:800  --/gpu:0 time: 7\n",
            "matrix shape:900  --/gpu:0 time: 7\n",
            "matrix shape:100  --/cpu:0 time: 13\n",
            "matrix shape:200  --/cpu:0 time: 7\n",
            "matrix shape:300  --/cpu:0 time: 8\n",
            "matrix shape:400  --/cpu:0 time: 8\n",
            "matrix shape:500  --/cpu:0 time: 8\n",
            "matrix shape:600  --/cpu:0 time: 7\n",
            "matrix shape:700  --/cpu:0 time: 7\n",
            "matrix shape:800  --/cpu:0 time: 15\n",
            "matrix shape:900  --/cpu:0 time: 8\n",
            "GPU time[678, 6, 7, 7, 6, 6, 4, 7, 7]\n",
            "CPU time[13, 7, 8, 8, 8, 7, 7, 15, 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkeopoL47G_B",
        "colab_type": "text"
      },
      "source": [
        "Lets plot the results here. It clearly shows that GPU is faster than CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "Yz1jBMF67G_D",
        "colab_type": "code",
        "outputId": "9999010f-722a-409c-87d3-54c8ff01d85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(matrix_sizes[:len(time_values_gpu)], time_values_gpu, label='GPU')\n",
        "plt.plot(matrix_sizes[:len(time_values_cpu)], time_values_cpu, label='CPU')\n",
        "plt.ylabel('Time (sec)')\n",
        "plt.xlabel('Size of Matrix ')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJYpBsRA7G_X",
        "colab_type": "text"
      },
      "source": [
        "#### When should not use GPU?\n",
        "\n",
        "GPUs don’t have direct access to the rest of your computer (except, of course for the display). Due to this, if you are running a command on a GPU, you need to copy all of the data to the GPU first, then do the operation, then copy the result back to your computer’s main memory. TensorFlow handles this under the hood, so the code is simple, but the work still needs to be performed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfNDe-mQ7G_a",
        "colab_type": "text"
      },
      "source": [
        "## Want to learn more?\n",
        "\n",
        "Running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBM's Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The PowerAI platform supports popular machine learning libraries and dependencies including Tensorflow, Caffe, Torch, and Theano. You can download a [free version of PowerAI](https://cocl.us/DX0108EN-PowerAI)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgYmDe9d7G_d",
        "colab_type": "text"
      },
      "source": [
        "### Thanks for completing this lesson!\n",
        "\n",
        "\n",
        "<h3>Authors:</h3>\n",
        "<article class=\"teacher\">\n",
        "<div class=\"teacher-image\" style=\"    float: left;\n",
        "    width: 115px;\n",
        "    height: 115px;\n",
        "    margin-right: 10px;\n",
        "    margin-bottom: 10px;\n",
        "    border: 1px solid #CCC;\n",
        "    padding: 3px;\n",
        "    border-radius: 3px;\n",
        "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://media.licdn.com/mpr/mpr/shrinknp_400_400/AAEAAQAAAAAAAAyFAAAAJGJlM2I2MmQzLTkxOWQtNDVhZi1hZGU0LWNlOWQzZDcyYjQ3ZA.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
        "<h4>Saeed Aghabozorgi</h4>\n",
        "<p><a href=\"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>, PhD is a Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients’ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
        "</article>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHO0r9OE7G_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}